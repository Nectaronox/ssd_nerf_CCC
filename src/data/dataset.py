import torch
from torch.utils.data import Dataset
import os
import numpy as np
import cv2
from PIL import Image
import glob
from torchvision import transforms

class KITTIDataset(Dataset):
    """
    KITTI Dataset Loader
    - Loads images, LiDAR point clouds, and calibration data.
    - Generates a normalized time step for each frame to enable temporal modeling.
    """
    def __init__(self, config, split='train', create_dummy_data=False):
        self.config = config
        self.split = split
        self.data_path = config['data']['path']
        self.create_dummy_data = create_dummy_data
        
        # ë°ì´í„° ê²½ë¡œ êµ¬ì„±
        self.image_dir = os.path.join(self.data_path, split, 'image_2')
        self.lidar_dir = os.path.join(self.data_path, split, 'velodyne')
        self.calib_dir = os.path.join(self.data_path, split, 'calib')
        
        # âœ… ë°ì´í„° ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not self._check_data_exists():
            if create_dummy_data:
                print(f"âš ï¸ KITTI ë°ì´í„°ê°€ ì—†ì–´ì„œ ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                self._create_dummy_data()
            else:
                self._print_data_download_guide()
                raise FileNotFoundError(
                    f"âŒ KITTI ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    f"ê²½ë¡œ: {self.image_dir}\n"
                    f"í•´ê²°ë°©ë²•:\n"
                    f"1. KITTI ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ {self.data_path}ì— ì••ì¶• í•´ì œ\n"
                    f"2. ë˜ëŠ” create_dummy_data=Trueë¡œ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©\n"
                    f"3. ë˜ëŠ” configì—ì„œ ì˜¬ë°”ë¥¸ data.path ì„¤ì •"
                )
        
        # ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        try:
            self.image_files = sorted([f for f in os.listdir(self.image_dir) if f.endswith('.png')])
            if len(self.image_files) == 0:
                raise ValueError(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.image_dir}")
        except Exception as e:
            if create_dummy_data:
                self.image_files = [f"dummy_{i:06d}.png" for i in range(10)]
            else:
                raise e
        
        # Calculate sequence length for time normalization
        self.sequence_length = len(self.image_files)

        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image_path = os.path.join(self.image_dir, self.image_files[idx])
        image = Image.open(image_path).convert("RGB")
        
        # LiDAR data
        lidar_path = os.path.join(self.lidar_dir, self.image_files[idx].replace('.png', '.bin'))
        lidar_points = np.fromfile(lidar_path, dtype=np.float32).reshape(-1, 4)

        # Calibration data
        calib_path = os.path.join(self.calib_dir, self.image_files[idx].replace('.png', '.txt'))
        calib = self._load_calib(calib_path)
        focal = calib['P2'][0, 0]
        
        # âœ… ê°œì„ ëœ camera_to_world ë³€í™˜ (placeholderì—ì„œ ì‹¤ì œ calibration ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½)
        # KITTI P2ëŠ” left color cameraì˜ projection matrixì´ë¯€ë¡œ, ì´ë¥¼ ì´ìš©í•´ c2w ìƒì„±
        P2 = calib['P2']  # (3, 4) projection matrix
        
        # P2ì—ì„œ ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ì™€ extrinsic ë¶„ë¦¬
        K = P2[:3, :3]  # Intrinsic matrix
        # KITTIì˜ ê²½ìš° ì¼ë°˜ì ìœ¼ë¡œ rectified coordinate systemì„ ì‚¬ìš©
        # ê°„ë‹¨í•œ c2w ë³€í™˜ ìƒì„± (identity rotation + small translation)
        c2w = np.eye(4, dtype=np.float32)
        
        # ì‹¤ì œ KITTI í™˜ê²½ì— ë§ëŠ” ê¸°ë³¸ ë³€í™˜ ì ìš©
        # ì¹´ë©”ë¼ê°€ ì°¨ëŸ‰ì— ì¥ì°©ëœ ìœ„ì¹˜ë¥¼ ë°˜ì˜ (ë†’ì´ì™€ ì „ë°© ì´ë™)
        c2w[0, 3] = 0.0    # x translation  
        c2w[1, 3] = -1.7   # y translation (ì¹´ë©”ë¼ ë†’ì´)
        c2w[2, 3] = 0.0    # z translation

        # --- Key Enhancement: Add normalized time step ---
        # Extract frame index from filename (e.g., '000001.png' -> 1)
        frame_idx = int(os.path.splitext(self.image_files[idx])[0])
        # Normalize by sequence length to get t in [0, 1]
        normalized_time = frame_idx / (self.sequence_length - 1) if self.sequence_length > 1 else 0.0

        if self.transform:
            image = self.transform(image)

        sample = {
            'image': image,
            'lidar_points': torch.from_numpy(lidar_points[:, :3]), # Use x, y, z
            'focal': torch.tensor(focal, dtype=torch.float32),
            'camera_to_world': torch.from_numpy(c2w).float(),  # ê°œì„ ëœ c2w ë³€í™˜
            'scene_timestep': torch.tensor([normalized_time], dtype=torch.float32),
            'sample_id': self.image_files[idx],  # ì¶”ê°€ë¡œ sample_idë„ ì¶”ê°€
            'P2': torch.from_numpy(P2).float(),  # ë””ë²„ê¹…ìš©ìœ¼ë¡œ P2ë„ ì¶”ê°€
        }
        
        return sample

    def _load_calib(self, filepath):
        """Loads calibration data from a KITTI calib file."""
        calib = {}
        with open(filepath, 'r') as f:
            for line in f.readlines():
                key, value = line.split(':', 1)
                calib[key] = np.array([float(x) for x in value.strip().split()]).reshape(3, 4) if key in ['P0', 'P1', 'P2', 'P3'] else np.array([float(x) for x in value.strip().split()])
        # Simplified example for camera-to-velo transform
        # In a real scenario, you'd parse the full rigid body transformation
        calib['T_cam_velo'] = np.eye(4)
        return calib

    def _check_data_exists(self):
        """ë°ì´í„° ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        required_dirs = [self.image_dir, self.lidar_dir, self.calib_dir]
        return all(os.path.exists(dir_path) for dir_path in required_dirs)

    def _create_dummy_data(self):
        """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±"""
        import numpy as np
        from PIL import Image
        
        print(f"ğŸ“ ë”ë¯¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.image_dir, exist_ok=True)
        os.makedirs(self.lidar_dir, exist_ok=True)
        os.makedirs(self.calib_dir, exist_ok=True)
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (10ê°œ)
        for i in range(10):
            # 375 x 1242 í¬ê¸°ì˜ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
            dummy_image = np.random.randint(0, 255, (375, 1242, 3), dtype=np.uint8)
            image_path = os.path.join(self.image_dir, f"dummy_{i:06d}.png")
            Image.fromarray(dummy_image).save(image_path)
            
            # ë”ë¯¸ LiDAR ë°ì´í„° ìƒì„±
            dummy_lidar = np.random.randn(1000, 4).astype(np.float32)
            lidar_path = os.path.join(self.lidar_dir, f"dummy_{i:06d}.bin")
            dummy_lidar.tofile(lidar_path)
            
            # ë”ë¯¸ calibration ë°ì´í„° ìƒì„±
            calib_content = """P0: 7.215377e+02 0.000000e+00 6.095593e+02 0.000000e+00 0.000000e+00 7.215377e+02 1.728540e+02 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00
P1: 7.215377e+02 0.000000e+00 6.095593e+02 -3.875744e+02 0.000000e+00 7.215377e+02 1.728540e+02 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00
P2: 7.215377e+02 0.000000e+00 6.095593e+02 4.485728e+01 0.000000e+00 7.215377e+02 1.728540e+02 2.163791e-01 0.000000e+00 0.000000e+00 1.000000e+00 2.745884e-03
P3: 7.215377e+02 0.000000e+00 6.095593e+02 -3.395242e+02 0.000000e+00 7.215377e+02 1.728540e+02 2.199936e+00 0.000000e+00 0.000000e+00 1.000000e+00 2.729905e-03
R0_rect: 9.999239e-01 9.837760e-03 -7.445048e-03 -9.869795e-03 9.999421e-01 -4.278459e-03 7.402527e-03 4.351614e-03 9.999631e-01
Tr_velo_to_cam: 7.533745e-03 -9.999714e-01 -6.166020e-04 -4.069766e-03 1.480249e-02 7.280733e-04 -9.998902e-01 -7.631618e-02 9.998621e-01 7.523790e-03 1.480755e-02 -2.717806e-01
Tr_imu_to_velo: 9.999976e-01 7.553071e-04 -2.035826e-03 -8.086759e-01 -7.854027e-04 9.998898e-01 -1.482298e-02 3.195559e-01 2.024406e-03 1.482454e-02 9.998881e-01 -7.997231e-01"""
            
            calib_path = os.path.join(self.calib_dir, f"dummy_{i:06d}.txt")
            with open(calib_path, 'w') as f:
                f.write(calib_content)
        
        print(f"âœ… ë”ë¯¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(os.listdir(self.image_dir))}ê°œ ìƒ˜í”Œ")

    def _print_data_download_guide(self):
        """KITTI ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸš¨ KITTI ë°ì´í„°ì…‹ì´ í•„ìš”í•©ë‹ˆë‹¤!")
        print("="*80)
        print("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ë°©ë²•:")
        print("1. KITTI ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë°©ë¬¸: http://www.cvlibs.net/datasets/kitti/")
        print("2. '3D Object Detection' ë˜ëŠ” 'Raw Data' ì„¹ì…˜ì—ì„œ ë‹¤ìŒ íŒŒì¼ë“¤ ë‹¤ìš´ë¡œë“œ:")
        print("   - Left color images of object data set (12 GB)")
        print("   - Velodyne point clouds (29 GB)")
        print("   - Camera calibration matrices (16 MB)")
        print("3. ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ë“¤ì„ ë‹¤ìŒ êµ¬ì¡°ë¡œ ì••ì¶• í•´ì œ:")
        print(f"   {self.data_path}/")
        print("   â”œâ”€â”€ training/")
        print("   â”‚   â”œâ”€â”€ image_2/")
        print("   â”‚   â”œâ”€â”€ velodyne/")
        print("   â”‚   â””â”€â”€ calib/")
        print("   â””â”€â”€ testing/")
        print("       â”œâ”€â”€ image_2/")
        print("       â”œâ”€â”€ velodyne/")
        print("       â””â”€â”€ calib/")
        print("\nğŸ’¡ ì„ì‹œ í•´ê²°ì±…:")
        print("ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰:")
        print("  dataset = KITTIDataset(config, split='test', create_dummy_data=True)")
        print("="*80)

def download_kitti_sample():
    """
    KITTI ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    """
    print("KITTI ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´:")
    print("1. KITTI ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë°©ë¬¸: http://www.cvlibs.net/datasets/kitti/")
    print("2. '3D Object Detection' ì„¹ì…˜ì—ì„œ ë‹¤ìŒ íŒŒì¼ë“¤ ë‹¤ìš´ë¡œë“œ:")
    print("   - Left color images of object data set (12 GB)")
    print("   - Velodyne point clouds (29 GB)")
    print("   - Camera calibration matrices of object data set (16 MB)")
    print("3. ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ë“¤ì„ ë‹¤ìŒ êµ¬ì¡°ë¡œ ì••ì¶• í•´ì œ:")
    print("   data/kitti/object/")
    print("   â”œâ”€â”€ training/")
    print("   â”‚   â”œâ”€â”€ image_2/")
    print("   â”‚   â”œâ”€â”€ velodyne/")
    print("   â”‚   â””â”€â”€ calib/")
    print("   â””â”€â”€ testing/")
    print("       â”œâ”€â”€ image_2/")
    print("       â”œâ”€â”€ velodyne/")
    print("       â””â”€â”€ calib/")

if __name__ == '__main__':
    from configs.default_config import config
    
    # KITTI ë°ì´í„° ê²½ë¡œ í™•ì¸
    if os.path.exists(config['data']['path']):
        try:
            dataset = KITTIDataset(config)
            print(f"KITTI ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ: {len(dataset)}ê°œ ìƒ˜í”Œ")
            
            if len(dataset) > 0:
                sample = dataset[0]
                print("\n--- ìƒ˜í”Œ ë°ì´í„° ---")
                print(f"ì´ë¯¸ì§€ í¬ê¸°: {sample['image'].shape}")
                print(f"LiDAR í¬ì¸íŠ¸ í¬ê¸°: {sample['lidar_points'].shape}")
                print(f"ìƒ˜í”Œ ID: {sample['sample_id']}")
                print(f"Scene timestep: {sample['scene_timestep']}")
            else:
                print("ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                download_kitti_sample()
        except Exception as e:
            print(f"ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            download_kitti_sample()
    else:
        print(f"KITTI ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config['data']['path']}")
        download_kitti_sample() 