#!/usr/bin/env python3
"""
ë‹¤ë¥¸ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
KITTIë¡œ í›ˆë ¨í•œ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import requests
import zipfile
import tarfile
import json
from pathlib import Path
from tqdm import tqdm
import argparse
import logging
import numpy as np
from urllib.parse import urlparse

# ë‹¤ì–‘í•œ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹ URLs
DATASETS = {
    'nuscenes_mini': {
        'name': 'nuScenes Mini Dataset',
        'description': 'ë³´ìŠ¤í„´/ì‹±ê°€í¬ë¥´ ë„ì‹œ í™˜ê²½, KITTIì™€ ë‹¤ë¥¸ ì„¼ì„œ êµ¬ì„±',
        'url': 'https://www.nuscenes.org/data/v1.0-mini.tgz',
        'size': '1.7GB',
        'scenes': 10,
        'location': 'ë³´ìŠ¤í„´, ì‹±ê°€í¬ë¥´',
        'weather': 'ë§‘ìŒ, ë¹„',
    },
    'waymo_sample': {
        'name': 'Waymo Open Dataset Sample',
        'description': 'ë¯¸êµ­ ì„œë¶€ ì§€ì—­, ë‹¤ì–‘í•œ ë‚ ì”¨ ì¡°ê±´',
        'url': 'https://console.cloud.google.com/storage/browser/waymo_open_dataset_v_1_4_2',
        'size': '500MB (ìƒ˜í”Œ)',
        'scenes': 20,
        'location': 'ë¯¸êµ­ ì„œë¶€ (ìº˜ë¦¬í¬ë‹ˆì•„, ì• ë¦¬ì¡°ë‚˜ ë“±)',
        'weather': 'ë§‘ìŒ, ë¹„, ì•ˆê°œ',
    },
    'once_sample': {
        'name': 'ONCE Dataset Sample',
        'description': 'ì¤‘êµ­ ë„ì‹œ í™˜ê²½, ì•„ì‹œì•„ ì§€ì—­ íŠ¹ì„±',
        'url': 'https://once-for-auto-driving.github.io/download.html',
        'size': '300MB (ìƒ˜í”Œ)',
        'scenes': 15,
        'location': 'ì¤‘êµ­ (ë² ì´ì§•, ìƒí•˜ì´ ë“±)',
        'weather': 'ë§‘ìŒ, íë¦¼',
    },
    'a2d2_sample': {
        'name': 'Audi A2D2 Sample',
        'description': 'ë…ì¼ ì•„ìš°í† ë°˜, ìœ ëŸ½ ë„ë¡œ í™˜ê²½',
        'url': 'https://www.a2d2.audi/a2d2/en/download.html',
        'size': '400MB (ìƒ˜í”Œ)',
        'scenes': 12,
        'location': 'ë…ì¼ (ì•„ìš°í† ë°˜, ì‹œë‚´)',
        'weather': 'ë§‘ìŒ, íë¦¼',
    },
    'cadc_winter': {
        'name': 'CADC Winter Dataset',
        'description': 'ìºë‚˜ë‹¤ ê²¨ìš¸ í™˜ê²½, ëˆˆ/ì–¼ìŒ ì¡°ê±´',
        'url': 'http://cadcd.uwaterloo.ca/downloads/',
        'size': '200MB (ìƒ˜í”Œ)',
        'scenes': 8,
        'location': 'ìºë‚˜ë‹¤ (ì›Œí„¸ë£¨)',
        'weather': 'ëˆˆ, ì–¼ìŒ, ì¶”ìœ„',
    },
    'oxford_robotcar': {
        'name': 'Oxford RobotCar Sample',
        'description': 'ì˜êµ­ ì˜¥ìŠ¤í¬ë“œ, 1ë…„ê°„ ê°™ì€ ê²½ë¡œ ë°˜ë³µ',
        'url': 'https://robotcar-dataset.robots.ox.ac.uk/downloads/',
        'size': '300MB (ìƒ˜í”Œ)',
        'scenes': 10,
        'location': 'ì˜êµ­ ì˜¥ìŠ¤í¬ë“œ',
        'weather': 'ë§‘ìŒ, ë¹„, ëˆˆ, ì•ˆê°œ',
    }
}

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
        ]
    )
    return logging.getLogger(__name__)

def show_available_datasets():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ í‘œì‹œ"""
    logger = logging.getLogger(__name__)
    
    print("\n" + "="*80)
    print("ğŸŒ ì‚¬ìš© ê°€ëŠ¥í•œ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹")
    print("="*80)
    
    for dataset_key, info in DATASETS.items():
        print(f"\nğŸ“Š {dataset_key.upper()}")
        print(f"  â€¢ ì´ë¦„: {info['name']}")
        print(f"  â€¢ ì„¤ëª…: {info['description']}")
        print(f"  â€¢ í¬ê¸°: {info['size']}")
        print(f"  â€¢ ì”¬ ìˆ˜: {info['scenes']}")
        print(f"  â€¢ ìœ„ì¹˜: {info['location']}")
        print(f"  â€¢ ë‚ ì”¨: {info['weather']}")
    
    print("\nğŸ’¡ ì‚¬ìš©ë²•:")
    print("  python scripts/download_other_datasets.py --dataset nuscenes_mini")
    print("  python scripts/download_other_datasets.py --dataset waymo_sample")
    print("  python scripts/download_other_datasets.py --dataset all  # ëª¨ë“  ë°ì´í„°ì…‹")
    print("="*80)

def download_file_with_progress(url, destination, chunk_size=8192):
    """ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ë©° íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    logger = logging.getLogger(__name__)
    
    try:
        logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {os.path.basename(destination)}")
        
        response = requests.get(url, stream=True, allow_redirects=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        os.makedirs(os.path.dirname(destination), exist_ok=True)
        
        with open(destination, 'wb') as file:
            if total_size > 0:
                with tqdm(
                    desc=os.path.basename(destination),
                    total=total_size,
                    unit='B',
                    unit_scale=True,
                    unit_divisor=1024,
                ) as pbar:
                    for chunk in response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            file.write(chunk)
                            pbar.update(len(chunk))
            else:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        file.write(chunk)
        
        logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {destination}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def check_dependencies():
    """í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ë° ì„¤ì¹˜ ì•ˆë‚´"""
    logger = logging.getLogger(__name__)
    
    missing_deps = []
    
    try:
        import numpy as np
    except ImportError:
        missing_deps.append('numpy')
    
    try:
        from PIL import Image, ImageDraw, ImageFilter
    except ImportError:
        missing_deps.append('pillow')
    
    try:
        import requests
    except ImportError:
        missing_deps.append('requests')
    
    try:
        from tqdm import tqdm
    except ImportError:
        missing_deps.append('tqdm')
    
    if missing_deps:
        logger.error("âŒ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:")
        for dep in missing_deps:
            logger.error(f"  - {dep}")
        logger.error("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        logger.error("pip install numpy pillow requests tqdm")
        logger.error("ë˜ëŠ”:")
        logger.error("pip install -r requirements.txt")
        return False
    
    logger.info("âœ… ëª¨ë“  í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    return True

def create_synthetic_diverse_data(output_dir, dataset_name, num_samples=20):
    """
    ë‹¤ì–‘í•œ í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í•©ì„± ë°ì´í„° ìƒì„±
    
    Args:
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
        dataset_name (str): ë°ì´í„°ì…‹ ì´ë¦„
        num_samples (int): ìƒì„±í•  ìƒ˜í”Œ ìˆ˜
    """
    logger = logging.getLogger(__name__)
    
    try:
        # ì˜ì¡´ì„± í™•ì¸
        import numpy as np
        from PIL import Image, ImageDraw, ImageFilter
        logger.info("ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ")
        
    except ImportError as e:
        logger.error(f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")
        logger.error("ğŸ’¡ í•´ê²° ë°©ë²•: pip install numpy pillow")
        return False
    
    logger.info(f"ğŸ¨ {dataset_name} ìŠ¤íƒ€ì¼ í•©ì„± ë°ì´í„° ìƒì„± ì‹œì‘...")
    logger.info(f"ğŸ“‚ ì¶œë ¥ ê²½ë¡œ: {output_dir}")
    logger.info(f"ğŸ”¢ ìƒ˜í”Œ ìˆ˜: {num_samples}")
    
    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
        os.makedirs(output_dir, exist_ok=True)
        test_file = os.path.join(output_dir, 'test_write_permission.tmp')
        with open(test_file, 'w') as f:
            f.write('test')
        os.remove(test_file)
        logger.info("âœ… ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ í™•ì¸ ì™„ë£Œ")
        
    except PermissionError:
        logger.error(f"âŒ ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {output_dir}")
        logger.error("ğŸ’¡ í•´ê²° ë°©ë²•: ë‹¤ë¥¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
        return False
    except Exception as e:
        logger.error(f"âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        return False
    
    try:
        # ë°ì´í„°ì…‹ë³„ íŠ¹ì„± ì •ì˜
        dataset_styles = {
            'nuscenes_mini': {
                'bg_colors': [(50, 50, 100), (30, 30, 80), (70, 70, 120)],  # ë„ì‹œ ë°¤/ì €ë…
                'weather': 'urban_night',
                'road_color': (40, 40, 40),
                'building_colors': [(100, 100, 100), (80, 80, 80), (120, 120, 120)],
            },
            'waymo_sample': {
                'bg_colors': [(135, 206, 235), (176, 196, 222), (205, 220, 237)],  # ë§‘ì€ ì„œë¶€ í•˜ëŠ˜
                'weather': 'clear_desert',
                'road_color': (169, 169, 169),
                'building_colors': [(210, 180, 140), (188, 143, 143), (160, 82, 45)],
            },
            'once_sample': {
                'bg_colors': [(200, 200, 200), (180, 180, 180), (160, 160, 160)],  # ì•ˆê°œ/ìŠ¤ëª¨ê·¸
                'weather': 'smoggy',
                'road_color': (100, 100, 100),
                'building_colors': [(120, 120, 120), (100, 100, 100), (140, 140, 140)],
            },
            'a2d2_sample': {
                'bg_colors': [(135, 206, 235), (173, 216, 230), (240, 248, 255)],  # ìœ ëŸ½ í•˜ëŠ˜
                'weather': 'european',
                'road_color': (50, 50, 50),  # ì•„ìŠ¤íŒ”íŠ¸
                'building_colors': [(139, 69, 19), (160, 82, 45), (210, 180, 140)],
            },
            'cadc_winter': {
                'bg_colors': [(248, 248, 255), (230, 230, 250), (211, 211, 211)],  # ê²¨ìš¸ í•˜ëŠ˜
                'weather': 'winter',
                'road_color': (245, 245, 245),  # ëˆˆ ë®ì¸ ë„ë¡œ
                'building_colors': [(176, 196, 222), (192, 192, 192), (169, 169, 169)],
            },
            'oxford_robotcar': {
                'bg_colors': [(119, 136, 153), (128, 128, 128), (105, 105, 105)],  # ì˜êµ­ íë¦° í•˜ëŠ˜
                'weather': 'rainy',
                'road_color': (105, 105, 105),
                'building_colors': [(139, 69, 19), (160, 82, 45), (205, 133, 63)],
            }
        }
        
        style = dataset_styles.get(dataset_name, dataset_styles['waymo_sample'])
        logger.info(f"ğŸ¨ ìŠ¤íƒ€ì¼ ì ìš©: {style['weather']} í™˜ê²½")
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        splits = ['training', 'testing']
        for split in splits:
            for subdir in ['image_2', 'velodyne', 'calib']:
                dir_path = os.path.join(output_dir, split, subdir)
                os.makedirs(dir_path, exist_ok=True)
        
        logger.info("ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ")
        
        # ê° splitë³„ ë°ì´í„° ìƒì„±
        for split in splits:
            logger.info(f"ğŸ“‚ {split} ë°ì´í„° ìƒì„± ì¤‘...")
            
            image_dir = os.path.join(output_dir, split, 'image_2')
            velodyne_dir = os.path.join(output_dir, split, 'velodyne')
            calib_dir = os.path.join(output_dir, split, 'calib')
            
            split_samples = num_samples if split == 'training' else max(1, num_samples // 2)
            
            for i in range(split_samples):
                try:
                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                    if i % 5 == 0:
                        logger.info(f"  ìƒ˜í”Œ {i+1}/{split_samples} ìƒì„± ì¤‘...")
                    
                    # 1. í™˜ê²½ë³„ íŠ¹ì„±ì´ ë°˜ì˜ëœ ì´ë¯¸ì§€ ìƒì„±
                    bg_color = style['bg_colors'][i % len(style['bg_colors'])]
                    
                    # ì•ˆì „í•œ ì´ë¯¸ì§€ ìƒì„±
                    img = Image.new('RGB', (1242, 375), color=bg_color)
                    draw = ImageDraw.Draw(img)
                    
                    # ë„ë¡œ ê·¸ë¦¬ê¸°
                    road_y = 250 + np.random.randint(-20, 20)
                    draw.rectangle([0, road_y, 1242, 375], fill=style['road_color'])
                    
                    # í™˜ê²½ë³„ íŠ¹ìˆ˜ íš¨ê³¼ (ì•ˆì „í•˜ê²Œ)
                    if style['weather'] == 'winter':
                        # ëˆˆ íš¨ê³¼
                        for _ in range(min(200, 100)):  # ì œí•œëœ ìˆ˜
                            x = np.random.randint(0, 1242)
                            y = np.random.randint(0, 375)
                            draw.ellipse([x-2, y-2, x+2, y+2], fill=(255, 255, 255))
                    
                    elif style['weather'] == 'rainy':
                        # ë¹„ íš¨ê³¼
                        for _ in range(min(150, 75)):  # ì œí•œëœ ìˆ˜
                            x = np.random.randint(0, 1242)
                            y = np.random.randint(0, 375)
                            draw.line([x, y, x+2, y+10], fill=(200, 200, 255), width=1)
                    
                    elif style['weather'] == 'urban_night':
                        # ë„ì‹œ ì¡°ëª… íš¨ê³¼
                        for _ in range(min(50, 25)):  # ì œí•œëœ ìˆ˜
                            x = np.random.randint(0, 1242)
                            y = np.random.randint(0, road_y)
                            color = (255, 255, 0) if np.random.random() > 0.5 else (255, 255, 255)
                            draw.ellipse([x-3, y-3, x+3, y+3], fill=color)
                    
                    # ê±´ë¬¼/ë¬¼ì²´ ê·¸ë¦¬ê¸° (ì œí•œëœ ìˆ˜)
                    for j in range(min(5, np.random.randint(3, 6))):
                        x = np.random.randint(0, 1000)
                        y = np.random.randint(50, max(51, road_y-50))
                        w = np.random.randint(50, 150)
                        h = np.random.randint(50, max(51, road_y-y))
                        color = style['building_colors'][j % len(style['building_colors'])]
                        # ìƒ‰ìƒ ë³€í™” ì œí•œ
                        color = tuple(np.clip(np.array(color) + np.random.randint(-20, 20, 3), 0, 255))
                        draw.rectangle([x, y, x+w, y+h], fill=color)
                    
                    # ì°¨ì„  ê·¸ë¦¬ê¸°
                    line_color = (255, 255, 255) if style['weather'] != 'winter' else (200, 200, 200)
                    for x in range(0, 1242, 100):
                        if style['weather'] == 'rainy' and np.random.random() > 0.7:
                            continue  # ë¹„ì˜¬ ë•Œ ì¼ë¶€ ì°¨ì„  ì•ˆ ë³´ì„
                        draw.rectangle([x, road_y+30, x+50, road_y+40], fill=line_color)
                    
                    # ë…¸ì´ì¦ˆ ì¶”ê°€ (ì œí•œì ìœ¼ë¡œ)
                    img_array = np.array(img)
                    
                    if style['weather'] == 'smoggy':
                        # ì•ˆê°œ/ìŠ¤ëª¨ê·¸ íš¨ê³¼ (ì œí•œì )
                        noise = np.random.normal(0, 10, img_array.shape)
                        img_array = np.clip(img_array + noise, 0, 255)
                    elif style['weather'] == 'winter':
                        # ê²¨ìš¸ ë°ê¸° ì¦ê°€ (ì œí•œì )
                        img_array = np.clip(img_array * 1.1, 0, 255)
                    
                    # ê¸°ë³¸ ë…¸ì´ì¦ˆ (ì œí•œì )
                    noise = np.random.normal(0, 5, img_array.shape)
                    img_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)
                    
                    final_img = Image.fromarray(img_array)
                    
                    # í™˜ê²½ë³„ ë¸”ëŸ¬ íš¨ê³¼ (ê°€ë²¼ìš´)
                    if style['weather'] in ['rainy', 'smoggy']:
                        final_img = final_img.filter(ImageFilter.GaussianBlur(radius=0.3))
                    
                    # ì´ë¯¸ì§€ ì €ì¥
                    img_path = os.path.join(image_dir, f"{i:06d}.png")
                    final_img.save(img_path, 'PNG')
                    
                    # 2. í™˜ê²½ë³„ LiDAR ë°ì´í„° ìƒì„± (ê°„ì†Œí™”)
                    num_points = min(15000, np.random.randint(10000, 12000))  # í¬ì¸íŠ¸ ìˆ˜ ì œí•œ
                    
                    # í™˜ê²½ë³„ í¬ì¸íŠ¸ ë°€ë„ ì¡°ì • (ê°„ì†Œí™”)
                    max_range = 80 if style['weather'] == 'winter' else 100
                    intensity_bias = 0.1 if style['weather'] == 'winter' else 0
                    
                    # ê±°ë¦¬ ë¶„í¬
                    distances = np.random.exponential(15, num_points)
                    distances = np.clip(distances, 2, max_range)
                    
                    # ê°ë„ ë¶„í¬
                    angles = np.random.uniform(-np.pi/4, np.pi/4, num_points)
                    
                    # 3D ì¢Œí‘œ
                    x = distances * np.sin(angles) + np.random.normal(0, 0.2, num_points)
                    z = distances * np.cos(angles) + np.random.normal(0, 0.2, num_points)
                    y = np.random.normal(-1.7, 0.3, num_points)
                    
                    # ë°˜ì‚¬ë„
                    intensity = np.random.uniform(0.2, 0.9, len(x))
                    intensity += intensity_bias
                    intensity = np.clip(intensity, 0.1, 1.0)
                    
                    # LiDAR ë°ì´í„° ì €ì¥
                    lidar_data = np.column_stack([x, y, z, intensity]).astype(np.float32)
                    lidar_path = os.path.join(velodyne_dir, f"{i:06d}.bin")
                    lidar_data.tofile(lidar_path)
                    
                    # 3. Calibration íŒŒì¼ (ê³ ì •ëœ í‘œì¤€ KITTI íŒŒë¼ë¯¸í„°)
                    calib_content = """P0: 7.215377e+02 0.000000e+00 6.095593e+02 0.000000e+00 0.000000e+00 7.215377e+02 1.728540e+02 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00
P1: 7.215377e+02 0.000000e+00 6.095593e+02 -3.875744e+02 0.000000e+00 7.215377e+02 1.728540e+02 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00
P2: 7.215377e+02 0.000000e+00 6.095593e+02 4.485728e+01 0.000000e+00 7.215377e+02 1.728540e+02 2.163791e-01 0.000000e+00 0.000000e+00 1.000000e+00 2.745884e-03
P3: 7.215377e+02 0.000000e+00 6.095593e+02 -3.395242e+02 0.000000e+00 7.215377e+02 1.728540e+02 2.199936e+00 0.000000e+00 0.000000e+00 1.000000e+00 2.729905e-03
R0_rect: 9.999239e-01 9.837760e-03 -7.445048e-03 -9.869795e-03 9.999421e-01 -4.278459e-03 7.402527e-03 4.351614e-03 9.999631e-01
Tr_velo_to_cam: 7.533745e-03 -9.999714e-01 -6.166020e-04 -4.069766e-03 1.480249e-02 7.280733e-04 -9.998902e-01 -7.631618e-02 9.998621e-01 7.523790e-03 1.480755e-02 -2.717806e-01
Tr_imu_to_velo: 9.999976e-01 7.553071e-04 -2.035826e-03 -8.086759e-01 -7.854027e-04 9.998898e-01 -1.482298e-02 3.195559e-01 2.024406e-03 1.482454e-02 9.998881e-01 -7.997231e-01"""
                    
                    calib_path = os.path.join(calib_dir, f"{i:06d}.txt")
                    with open(calib_path, 'w', encoding='utf-8') as f:
                        f.write(calib_content)
                
                except Exception as e:
                    logger.warning(f"âš ï¸ ìƒ˜í”Œ {i} ìƒì„± ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
                    continue
            
            logger.info(f"âœ… {split} ì™„ë£Œ: {split_samples}ê°œ ìƒ˜í”Œ")
        
        # ë°ì´í„°ì…‹ ì •ë³´ íŒŒì¼ ìƒì„±
        info = {
            'dataset_name': dataset_name,
            'description': DATASETS[dataset_name]['description'],
            'location': DATASETS[dataset_name]['location'],
            'weather': DATASETS[dataset_name]['weather'],
            'num_training_samples': num_samples,
            'num_testing_samples': max(1, num_samples // 2),
            'created_by': 'SSD-NeRF Synthetic Data Generator',
        }
        
        info_path = os.path.join(output_dir, 'dataset_info.json')
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ‰ {dataset_name} ìŠ¤íƒ€ì¼ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        logger.info(f"ğŸ“‚ ê²½ë¡œ: {output_dir}")
        logger.info(f"ğŸ“Š íŠ¹ì§•: {DATASETS[dataset_name]['weather']} í™˜ê²½, {DATASETS[dataset_name]['location']}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def download_dataset(dataset_name, output_dir, num_samples=20):
    """
    íŠ¹ì • ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ìƒì„±
    
    Args:
        dataset_name (str): ë°ì´í„°ì…‹ ì´ë¦„
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
        num_samples (int): ìƒì„±í•  ìƒ˜í”Œ ìˆ˜ (í•©ì„± ë°ì´í„°ì˜ ê²½ìš°)
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    logger = logging.getLogger(__name__)
    
    if dataset_name not in DATASETS:
        logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„°ì…‹: {dataset_name}")
        logger.info("ğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹:")
        for key in DATASETS.keys():
            logger.info(f"  - {key}")
        return False
    
    dataset_info = DATASETS[dataset_name]
    dataset_dir = os.path.join(output_dir, dataset_name)
    
    logger.info(f"ğŸš€ {dataset_info['name']} ì¤€ë¹„ ì‹œì‘")
    logger.info(f"ğŸ“ ì„¤ëª…: {dataset_info['description']}")
    logger.info(f"ğŸ“ ìœ„ì¹˜: {dataset_info['location']}")
    logger.info(f"ğŸŒ¤ï¸ ë‚ ì”¨: {dataset_info['weather']}")
    
    # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ëŒ€ë¶€ë¶„ì€ ì œí•œì ì´ë¯€ë¡œ í•©ì„± ë°ì´í„°ë¡œ ëŒ€ì²´)
    logger.info("ğŸ”„ ì‹¤ì œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œë„...")
    
    if dataset_name == 'nuscenes_mini':
        logger.warning("âš ï¸ nuScenesëŠ” ê³„ì • ë“±ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        logger.info("ğŸŒ ê³µì‹ ì‚¬ì´íŠ¸: https://www.nuscenes.org/nuscenes")
    elif dataset_name == 'waymo_sample':
        logger.warning("âš ï¸ WaymoëŠ” Google Cloud ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        logger.info("ğŸŒ ê³µì‹ ì‚¬ì´íŠ¸: https://waymo.com/open/")
    else:
        logger.warning("âš ï¸ í•´ë‹¹ ë°ì´í„°ì…‹ì€ ì œí•œì  ì ‘ê·¼ì…ë‹ˆë‹¤.")
    
    logger.info("ğŸ¨ ëŒ€ì‹  í•´ë‹¹ í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    
    # í•©ì„± ë°ì´í„° ìƒì„±
    create_synthetic_diverse_data(dataset_dir, dataset_name, num_samples)
    
    return True

def main():
    parser = argparse.ArgumentParser(
        description="ğŸŒ ë‹¤ì–‘í•œ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë”",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ ë³´ê¸°
  python scripts/download_other_datasets.py --list

  # íŠ¹ì • ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
  python scripts/download_other_datasets.py --dataset nuscenes_mini
  python scripts/download_other_datasets.py --dataset waymo_sample
  python scripts/download_other_datasets.py --dataset cadc_winter

  # ì—¬ëŸ¬ ë°ì´í„°ì…‹ í•œë²ˆì—
  python scripts/download_other_datasets.py --dataset nuscenes_mini waymo_sample

  # ëª¨ë“  ë°ì´í„°ì…‹
  python scripts/download_other_datasets.py --dataset all

  # ë” ë§ì€ ìƒ˜í”Œë¡œ
  python scripts/download_other_datasets.py --dataset nuscenes_mini --num_samples 50

ì¶”ì²œ ì‚¬ìš©ë²• (ëª¨ë¸ ì¼ë°˜í™” í…ŒìŠ¤íŠ¸):
  1. python scripts/download_other_datasets.py --dataset nuscenes_mini    # ë„ì‹œ í™˜ê²½
  2. python scripts/download_other_datasets.py --dataset cadc_winter     # ê²¨ìš¸ í™˜ê²½  
  3. python scripts/download_other_datasets.py --dataset oxford_robotcar # ë¹„ í™˜ê²½

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:
  pip install numpy pillow requests tqdm
        """
    )
    
    parser.add_argument('--dataset', nargs='+', 
                        choices=list(DATASETS.keys()) + ['all'],
                        help="ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ì…‹(ë“¤)")
    parser.add_argument('--output_dir', type=str, default='data/other_datasets',
                        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: data/other_datasets)")
    parser.add_argument('--num_samples', type=int, default=20,
                        help="ìƒì„±í•  ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸: 20)")
    parser.add_argument('--list', action='store_true',
                        help="ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ í‘œì‹œ")
    parser.add_argument('--verbose', action='store_true',
                        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    parser.add_argument('--check_deps', action='store_true',
                        help="ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸")
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging()
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # ì˜ì¡´ì„± í™•ì¸ ì˜µì…˜
    if args.check_deps:
        logger.info("ğŸ” ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ì¤‘...")
        if check_dependencies():
            logger.info("ğŸ‰ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
        return 0
    
    if args.list:
        show_available_datasets()
        return 0
    
    if not args.dataset:
        logger.error("âŒ ë°ì´í„°ì…‹ì„ ì§€ì •í•´ì£¼ì„¸ìš”. --listë¡œ ëª©ë¡ì„ í™•ì¸í•˜ì„¸ìš”.")
        logger.info("ğŸ’¡ ë¹ ë¥¸ ì‹œì‘: python scripts/download_other_datasets.py --dataset nuscenes_mini")
        return 1
    
    try:
        # ì˜ì¡´ì„± ë¨¼ì € í™•ì¸
        logger.info("ğŸ” í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ì¤‘...")
        if not check_dependencies():
            logger.error("ğŸ’¡ ë¨¼ì € í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
            logger.error("pip install numpy pillow requests tqdm")
            return 1
        
        logger.info("ğŸŒ ë‹¤ì–‘í•œ í™˜ê²½ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹œì‘")
        logger.info("ğŸ¯ ëª©ì : KITTI í›ˆë ¨ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        
        datasets_to_download = args.dataset
        if 'all' in datasets_to_download:
            datasets_to_download = list(DATASETS.keys())
        
        success_count = 0
        total_datasets = len(datasets_to_download)
        
        for idx, dataset_name in enumerate(datasets_to_download, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“Š [{idx}/{total_datasets}] {dataset_name.upper()} ì²˜ë¦¬ ì¤‘...")
            logger.info(f"{'='*60}")
            
            if download_dataset(dataset_name, args.output_dir, args.num_samples):
                success_count += 1
                logger.info(f"âœ… {dataset_name} ì™„ë£Œ")
            else:
                logger.error(f"âŒ {dataset_name} ì‹¤íŒ¨")
        
        logger.info(f"\nğŸ‰ ì™„ë£Œ! {success_count}/{total_datasets} ë°ì´í„°ì…‹ ì¤€ë¹„ë¨")
        logger.info(f"ğŸ“‚ ê²½ë¡œ: {os.path.abspath(args.output_dir)}")
        
        if success_count > 0:
            logger.info("\nğŸ’» ì‚¬ìš© ë°©ë²•:")
            logger.info("# ê° ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸:")
            for dataset_name in datasets_to_download[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                if dataset_name != 'all':
                    dataset_path = os.path.join(args.output_dir, dataset_name)
                    logger.info(f"python scripts/run_evaluation.py --config configs/default_config.py --data_path {dataset_path}")
            
            logger.info(f"\nğŸ“‹ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ ë°ì´í„°ì…‹: {success_count}ê°œ")
            logger.info("ğŸŒŸ ì´ì œ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        
        return 0 if success_count > 0 else 1
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        logger.error("\nğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        logger.error("1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸: python scripts/download_other_datasets.py --check_deps")
        logger.error("2. ì˜ì¡´ì„± ì„¤ì¹˜: pip install numpy pillow requests tqdm")
        logger.error("3. ê¶Œí•œ í™•ì¸: ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì‚¬ìš© ì‹œë„")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 