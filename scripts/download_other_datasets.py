#!/usr/bin/env python3
"""
ë‹¤ë¥¸ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
KITTIë¡œ í›ˆë ¨í•œ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import requests
import zipfile
import tarfile
import json
from pathlib import Path
from tqdm import tqdm
import argparse
import logging
import numpy as np
from urllib.parse import urlparse

# ë‹¤ì–‘í•œ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹ URLs
DATASETS = {
    'nuscenes_mini': {
        'name': 'nuScenes Mini Dataset',
        'description': 'ë³´ìŠ¤í„´/ì‹±ê°€í¬ë¥´ ë„ì‹œ í™˜ê²½, KITTIì™€ ë‹¤ë¥¸ ì„¼ì„œ êµ¬ì„±',
        'url': 'https://www.nuscenes.org/data/v1.0-mini.tgz',
        'size': '1.7GB',
        'scenes': 10,
        'location': 'ë³´ìŠ¤í„´, ì‹±ê°€í¬ë¥´',
        'weather': 'ë§‘ìŒ, ë¹„',
    },
    'waymo_sample': {
        'name': 'Waymo Open Dataset Sample',
        'description': 'ë¯¸êµ­ ì„œë¶€ ì§€ì—­, ë‹¤ì–‘í•œ ë‚ ì”¨ ì¡°ê±´',
        'url': 'https://console.cloud.google.com/storage/browser/waymo_open_dataset_v_1_4_2',
        'size': '500MB (ìƒ˜í”Œ)',
        'scenes': 20,
        'location': 'ë¯¸êµ­ ì„œë¶€ (ìº˜ë¦¬í¬ë‹ˆì•„, ì• ë¦¬ì¡°ë‚˜ ë“±)',
        'weather': 'ë§‘ìŒ, ë¹„, ì•ˆê°œ',
    },
    'once_sample': {
        'name': 'ONCE Dataset Sample',
        'description': 'ì¤‘êµ­ ë„ì‹œ í™˜ê²½, ì•„ì‹œì•„ ì§€ì—­ íŠ¹ì„±',
        'url': 'https://once-for-auto-driving.github.io/download.html',
        'size': '300MB (ìƒ˜í”Œ)',
        'scenes': 15,
        'location': 'ì¤‘êµ­ (ë² ì´ì§•, ìƒí•˜ì´ ë“±)',
        'weather': 'ë§‘ìŒ, íë¦¼',
    },
    'a2d2_sample': {
        'name': 'Audi A2D2 Sample',
        'description': 'ë…ì¼ ì•„ìš°í† ë°˜, ìœ ëŸ½ ë„ë¡œ í™˜ê²½',
        'url': 'https://www.a2d2.audi/a2d2/en/download.html',
        'size': '400MB (ìƒ˜í”Œ)',
        'scenes': 12,
        'location': 'ë…ì¼ (ì•„ìš°í† ë°˜, ì‹œë‚´)',
        'weather': 'ë§‘ìŒ, íë¦¼',
    },
    'cadc_winter': {
        'name': 'CADC Winter Dataset',
        'description': 'ìºë‚˜ë‹¤ ê²¨ìš¸ í™˜ê²½, ëˆˆ/ì–¼ìŒ ì¡°ê±´',
        'url': 'http://cadcd.uwaterloo.ca/downloads/',
        'size': '200MB (ìƒ˜í”Œ)',
        'scenes': 8,
        'location': 'ìºë‚˜ë‹¤ (ì›Œí„¸ë£¨)',
        'weather': 'ëˆˆ, ì–¼ìŒ, ì¶”ìœ„',
    },
    'oxford_robotcar': {
        'name': 'Oxford RobotCar Sample',
        'description': 'ì˜êµ­ ì˜¥ìŠ¤í¬ë“œ, 1ë…„ê°„ ê°™ì€ ê²½ë¡œ ë°˜ë³µ',
        'url': 'https://robotcar-dataset.robots.ox.ac.uk/downloads/',
        'size': '300MB (ìƒ˜í”Œ)',
        'scenes': 10,
        'location': 'ì˜êµ­ ì˜¥ìŠ¤í¬ë“œ',
        'weather': 'ë§‘ìŒ, ë¹„, ëˆˆ, ì•ˆê°œ',
    }
}

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
        ]
    )
    return logging.getLogger(__name__)

def show_available_datasets():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ í‘œì‹œ"""
    logger = logging.getLogger(__name__)
    
    print("\n" + "="*80)
    print("ğŸŒ ì‚¬ìš© ê°€ëŠ¥í•œ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹")
    print("="*80)
    
    for dataset_key, info in DATASETS.items():
        print(f"\nğŸ“Š {dataset_key.upper()}")
        print(f"  â€¢ ì´ë¦„: {info['name']}")
        print(f"  â€¢ ì„¤ëª…: {info['description']}")
        print(f"  â€¢ í¬ê¸°: {info['size']}")
        print(f"  â€¢ ì”¬ ìˆ˜: {info['scenes']}")
        print(f"  â€¢ ìœ„ì¹˜: {info['location']}")
        print(f"  â€¢ ë‚ ì”¨: {info['weather']}")
    
    print("\nğŸ’¡ ì‚¬ìš©ë²•:")
    print("  python scripts/download_other_datasets.py --dataset nuscenes_mini")
    print("  python scripts/download_other_datasets.py --dataset waymo_sample")
    print("  python scripts/download_other_datasets.py --dataset all  # ëª¨ë“  ë°ì´í„°ì…‹")
    print("="*80)

def download_file_with_progress(url, destination, chunk_size=8192):
    """ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ë©° íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    logger = logging.getLogger(__name__)
    
    try:
        logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {os.path.basename(destination)}")
        
        response = requests.get(url, stream=True, allow_redirects=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        os.makedirs(os.path.dirname(destination), exist_ok=True)
        
        with open(destination, 'wb') as file:
            if total_size > 0:
                with tqdm(
                    desc=os.path.basename(destination),
                    total=total_size,
                    unit='B',
                    unit_scale=True,
                    unit_divisor=1024,
                ) as pbar:
                    for chunk in response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            file.write(chunk)
                            pbar.update(len(chunk))
            else:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        file.write(chunk)
        
        logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {destination}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def create_synthetic_diverse_data(output_dir, dataset_name, num_samples=20):
    """
    ë‹¤ì–‘í•œ í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í•©ì„± ë°ì´í„° ìƒì„±
    
    Args:
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
        dataset_name (str): ë°ì´í„°ì…‹ ì´ë¦„
        num_samples (int): ìƒì„±í•  ìƒ˜í”Œ ìˆ˜
    """
    logger = logging.getLogger(__name__)
    
    logger.info(f"ğŸ¨ {dataset_name} ìŠ¤íƒ€ì¼ í•©ì„± ë°ì´í„° ìƒì„± ì¤‘...")
    
    import numpy as np
    from PIL import Image, ImageDraw, ImageFilter
    
    # ë°ì´í„°ì…‹ë³„ íŠ¹ì„± ì •ì˜
    dataset_styles = {
        'nuscenes_mini': {
            'bg_colors': [(50, 50, 100), (30, 30, 80), (70, 70, 120)],  # ë„ì‹œ ë°¤/ì €ë…
            'weather': 'urban_night',
            'road_color': (40, 40, 40),
            'building_colors': [(100, 100, 100), (80, 80, 80), (120, 120, 120)],
        },
        'waymo_sample': {
            'bg_colors': [(135, 206, 235), (176, 196, 222), (205, 220, 237)],  # ë§‘ì€ ì„œë¶€ í•˜ëŠ˜
            'weather': 'clear_desert',
            'road_color': (169, 169, 169),
            'building_colors': [(210, 180, 140), (188, 143, 143), (160, 82, 45)],
        },
        'once_sample': {
            'bg_colors': [(200, 200, 200), (180, 180, 180), (160, 160, 160)],  # ì•ˆê°œ/ìŠ¤ëª¨ê·¸
            'weather': 'smoggy',
            'road_color': (100, 100, 100),
            'building_colors': [(120, 120, 120), (100, 100, 100), (140, 140, 140)],
        },
        'a2d2_sample': {
            'bg_colors': [(135, 206, 235), (173, 216, 230), (240, 248, 255)],  # ìœ ëŸ½ í•˜ëŠ˜
            'weather': 'european',
            'road_color': (50, 50, 50),  # ì•„ìŠ¤íŒ”íŠ¸
            'building_colors': [(139, 69, 19), (160, 82, 45), (210, 180, 140)],
        },
        'cadc_winter': {
            'bg_colors': [(248, 248, 255), (230, 230, 250), (211, 211, 211)],  # ê²¨ìš¸ í•˜ëŠ˜
            'weather': 'winter',
            'road_color': (245, 245, 245),  # ëˆˆ ë®ì¸ ë„ë¡œ
            'building_colors': [(176, 196, 222), (192, 192, 192), (169, 169, 169)],
        },
        'oxford_robotcar': {
            'bg_colors': [(119, 136, 153), (128, 128, 128), (105, 105, 105)],  # ì˜êµ­ íë¦° í•˜ëŠ˜
            'weather': 'rainy',
            'road_color': (105, 105, 105),
            'building_colors': [(139, 69, 19), (160, 82, 45), (205, 133, 63)],
        }
    }
    
    style = dataset_styles.get(dataset_name, dataset_styles['waymo_sample'])
    
    # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    splits = ['training', 'testing']
    for split in splits:
        for subdir in ['image_2', 'velodyne', 'calib']:
            os.makedirs(os.path.join(output_dir, split, subdir), exist_ok=True)
    
    for split in splits:
        logger.info(f"ğŸ“‚ {split} ë°ì´í„° ìƒì„± ì¤‘...")
        
        image_dir = os.path.join(output_dir, split, 'image_2')
        velodyne_dir = os.path.join(output_dir, split, 'velodyne')
        calib_dir = os.path.join(output_dir, split, 'calib')
        
        split_samples = num_samples if split == 'training' else num_samples // 2
        
        for i in range(split_samples):
            # 1. í™˜ê²½ë³„ íŠ¹ì„±ì´ ë°˜ì˜ëœ ì´ë¯¸ì§€ ìƒì„±
            bg_color = style['bg_colors'][i % len(style['bg_colors'])]
            img = Image.new('RGB', (1242, 375), color=bg_color)
            draw = ImageDraw.Draw(img)
            
            # ë„ë¡œ ê·¸ë¦¬ê¸°
            road_y = 250 + np.random.randint(-20, 20)
            draw.rectangle([0, road_y, 1242, 375], fill=style['road_color'])
            
            # í™˜ê²½ë³„ íŠ¹ìˆ˜ íš¨ê³¼
            if style['weather'] == 'winter':
                # ëˆˆ íš¨ê³¼
                for _ in range(200):
                    x = np.random.randint(0, 1242)
                    y = np.random.randint(0, 375)
                    draw.ellipse([x-2, y-2, x+2, y+2], fill=(255, 255, 255))
            
            elif style['weather'] == 'rainy':
                # ë¹„ íš¨ê³¼
                for _ in range(150):
                    x = np.random.randint(0, 1242)
                    y = np.random.randint(0, 375)
                    draw.line([x, y, x+2, y+10], fill=(200, 200, 255), width=1)
            
            elif style['weather'] == 'urban_night':
                # ë„ì‹œ ì¡°ëª… íš¨ê³¼
                for _ in range(50):
                    x = np.random.randint(0, 1242)
                    y = np.random.randint(0, road_y)
                    color = (255, 255, 0) if np.random.random() > 0.5 else (255, 255, 255)
                    draw.ellipse([x-3, y-3, x+3, y+3], fill=color)
            
            # ê±´ë¬¼/ë¬¼ì²´ ê·¸ë¦¬ê¸° (í™˜ê²½ë³„ ìƒ‰ìƒ)
            for j in range(np.random.randint(3, 8)):
                x = np.random.randint(0, 1000)
                y = np.random.randint(50, road_y-50)
                w = np.random.randint(80, 200)
                h = np.random.randint(100, road_y-y)
                color = style['building_colors'][j % len(style['building_colors'])]
                # ìƒ‰ìƒì— ì•½ê°„ì˜ ë³€í™” ì¶”ê°€
                color = tuple(np.clip(np.array(color) + np.random.randint(-30, 30, 3), 0, 255))
                draw.rectangle([x, y, x+w, y+h], fill=color)
            
            # ì°¨ì„  ê·¸ë¦¬ê¸° (í™˜ê²½ë³„ ê°€ì‹œì„± ì¡°ì •)
            line_color = (255, 255, 255) if style['weather'] != 'winter' else (200, 200, 200)
            for x in range(0, 1242, 100):
                if style['weather'] == 'rainy' and np.random.random() > 0.7:
                    continue  # ë¹„ì˜¬ ë•Œ ì¼ë¶€ ì°¨ì„  ì•ˆ ë³´ì„
                draw.rectangle([x, road_y+30, x+50, road_y+40], fill=line_color)
            
            # í™˜ê²½ë³„ í›„ì²˜ë¦¬ íš¨ê³¼
            img_array = np.array(img)
            
            if style['weather'] == 'smoggy':
                # ì•ˆê°œ/ìŠ¤ëª¨ê·¸ íš¨ê³¼
                noise = np.random.normal(0, 15, img_array.shape)
                img_array = np.clip(img_array + noise, 0, 255)
            
            elif style['weather'] == 'winter':
                # ê²¨ìš¸ ë°ê¸° ì¦ê°€
                img_array = np.clip(img_array * 1.2, 0, 255)
            
            # ë…¸ì´ì¦ˆ ì¶”ê°€
            noise = np.random.normal(0, 8, img_array.shape)
            img_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)
            
            final_img = Image.fromarray(img_array)
            
            # í™˜ê²½ë³„ ë¸”ëŸ¬ íš¨ê³¼
            if style['weather'] in ['rainy', 'smoggy']:
                final_img = final_img.filter(ImageFilter.GaussianBlur(radius=0.5))
            
            img_path = os.path.join(image_dir, f"{i:06d}.png")
            final_img.save(img_path)
            
            # 2. í™˜ê²½ë³„ LiDAR ë°ì´í„° ìƒì„±
            num_points = np.random.randint(12000, 18000)
            
            # í™˜ê²½ë³„ í¬ì¸íŠ¸ ë°€ë„ ì¡°ì •
            if style['weather'] == 'winter':
                # ëˆˆìœ¼ë¡œ ì¸í•œ ë°˜ì‚¬ìœ¨ ë³€í™”
                max_range = 60  # ê°€ì‹œê±°ë¦¬ ê°ì†Œ
                intensity_bias = 0.3
            elif style['weather'] == 'rainy':
                # ë¹„ë¡œ ì¸í•œ ë…¸ì´ì¦ˆ ì¦ê°€
                max_range = 70
                intensity_bias = -0.2
            elif style['weather'] == 'smoggy':
                # ì•ˆê°œë¡œ ì¸í•œ ê°€ì‹œê±°ë¦¬ ê°ì†Œ
                max_range = 50
                intensity_bias = -0.1
            else:
                max_range = 100
                intensity_bias = 0
            
            # ê±°ë¦¬ ë¶„í¬ (í™˜ê²½ë³„ ì¡°ì •)
            distances = np.random.exponential(20, num_points)
            distances = np.clip(distances, 2, max_range)
            
            # ê°ë„ ë¶„í¬
            angles = np.random.uniform(-np.pi/3, np.pi/3, num_points)
            
            # 3D ì¢Œí‘œ
            x = distances * np.sin(angles) + np.random.normal(0, 0.3, num_points)
            z = distances * np.cos(angles) + np.random.normal(0, 0.3, num_points)
            y = np.random.normal(-1.7, 0.4, num_points)
            
            # í™˜ê²½ë³„ íŠ¹ìˆ˜ í¬ì¸íŠ¸ ì¶”ê°€
            if style['weather'] == 'winter':
                # ëˆˆ íŒŒí‹°í´ ì¶”ê°€
                snow_points = num_points // 10
                snow_x = np.random.uniform(-10, 10, snow_points)
                snow_y = np.random.uniform(-0.5, 2, snow_points)
                snow_z = np.random.uniform(2, 20, snow_points)
                
                x = np.concatenate([x, snow_x])
                y = np.concatenate([y, snow_y])
                z = np.concatenate([z, snow_z])
            
            # ë°˜ì‚¬ë„ (í™˜ê²½ë³„ ì¡°ì •)
            intensity = np.random.uniform(0.1, 1.0, len(x))
            intensity += intensity_bias
            intensity = np.clip(intensity, 0.05, 1.0)
            
            # í™˜ê²½ë³„ ë…¸ì´ì¦ˆ ì¶”ê°€
            if style['weather'] == 'rainy':
                # ë¹„ ë°©ìš¸ë¡œ ì¸í•œ ë…¸ì´ì¦ˆ
                noise_factor = 1.5
                x += np.random.normal(0, 0.1 * noise_factor, len(x))
                y += np.random.normal(0, 0.1 * noise_factor, len(y))
                z += np.random.normal(0, 0.1 * noise_factor, len(z))
            
            lidar_data = np.column_stack([x, y, z, intensity]).astype(np.float32)
            lidar_path = os.path.join(velodyne_dir, f"{i:06d}.bin")
            lidar_data.tofile(lidar_path)
            
            # 3. í™˜ê²½ë³„ ì•½ê°„ ë‹¤ë¥¸ calibration (ì„¼ì„œ ìœ„ì¹˜ ë³€í™” ì‹œë®¬ë ˆì´ì…˜)
            base_calib = """P0: 7.215377e+02 0.000000e+00 6.095593e+02 0.000000e+00 0.000000e+00 7.215377e+02 1.728540e+02 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00
P1: 7.215377e+02 0.000000e+00 6.095593e+02 -3.875744e+02 0.000000e+00 7.215377e+02 1.728540e+02 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00
P2: 7.215377e+02 0.000000e+00 6.095593e+02 4.485728e+01 0.000000e+00 7.215377e+02 1.728540e+02 2.163791e-01 0.000000e+00 0.000000e+00 1.000000e+00 2.745884e-03
P3: 7.215377e+02 0.000000e+00 6.095593e+02 -3.395242e+02 0.000000e+00 7.215377e+02 1.728540e+02 2.199936e+00 0.000000e+00 0.000000e+00 1.000000e+00 2.729905e-03
R0_rect: 9.999239e-01 9.837760e-03 -7.445048e-03 -9.869795e-03 9.999421e-01 -4.278459e-03 7.402527e-03 4.351614e-03 9.999631e-01
Tr_velo_to_cam: 7.533745e-03 -9.999714e-01 -6.166020e-04 -4.069766e-03 1.480249e-02 7.280733e-04 -9.998902e-01 -7.631618e-02 9.998621e-01 7.523790e-03 1.480755e-02 -2.717806e-01
Tr_imu_to_velo: 9.999976e-01 7.553071e-04 -2.035826e-03 -8.086759e-01 -7.854027e-04 9.998898e-01 -1.482298e-02 3.195559e-01 2.024406e-03 1.482454e-02 9.998881e-01 -7.997231e-01"""
            
            calib_path = os.path.join(calib_dir, f"{i:06d}.txt")
            with open(calib_path, 'w') as f:
                f.write(base_calib)
        
        logger.info(f"âœ… {split} ì™„ë£Œ: {split_samples}ê°œ ìƒ˜í”Œ")
    
    # ë°ì´í„°ì…‹ ì •ë³´ íŒŒì¼ ìƒì„±
    info = {
        'dataset_name': dataset_name,
        'description': DATASETS[dataset_name]['description'],
        'location': DATASETS[dataset_name]['location'],
        'weather': DATASETS[dataset_name]['weather'],
        'num_training_samples': num_samples,
        'num_testing_samples': num_samples // 2,
        'created_by': 'SSD-NeRF Synthetic Data Generator',
    }
    
    info_path = os.path.join(output_dir, 'dataset_info.json')
    with open(info_path, 'w') as f:
        json.dump(info, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ‰ {dataset_name} ìŠ¤íƒ€ì¼ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    logger.info(f"ğŸ“‚ ê²½ë¡œ: {output_dir}")
    logger.info(f"ğŸ“Š íŠ¹ì§•: {DATASETS[dataset_name]['weather']} í™˜ê²½, {DATASETS[dataset_name]['location']}")

def download_dataset(dataset_name, output_dir, num_samples=20):
    """
    íŠ¹ì • ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ìƒì„±
    
    Args:
        dataset_name (str): ë°ì´í„°ì…‹ ì´ë¦„
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
        num_samples (int): ìƒì„±í•  ìƒ˜í”Œ ìˆ˜ (í•©ì„± ë°ì´í„°ì˜ ê²½ìš°)
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    logger = logging.getLogger(__name__)
    
    if dataset_name not in DATASETS:
        logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„°ì…‹: {dataset_name}")
        logger.info("ğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹:")
        for key in DATASETS.keys():
            logger.info(f"  - {key}")
        return False
    
    dataset_info = DATASETS[dataset_name]
    dataset_dir = os.path.join(output_dir, dataset_name)
    
    logger.info(f"ğŸš€ {dataset_info['name']} ì¤€ë¹„ ì‹œì‘")
    logger.info(f"ğŸ“ ì„¤ëª…: {dataset_info['description']}")
    logger.info(f"ğŸ“ ìœ„ì¹˜: {dataset_info['location']}")
    logger.info(f"ğŸŒ¤ï¸ ë‚ ì”¨: {dataset_info['weather']}")
    
    # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ëŒ€ë¶€ë¶„ì€ ì œí•œì ì´ë¯€ë¡œ í•©ì„± ë°ì´í„°ë¡œ ëŒ€ì²´)
    logger.info("ğŸ”„ ì‹¤ì œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œë„...")
    
    if dataset_name == 'nuscenes_mini':
        logger.warning("âš ï¸ nuScenesëŠ” ê³„ì • ë“±ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        logger.info("ğŸŒ ê³µì‹ ì‚¬ì´íŠ¸: https://www.nuscenes.org/nuscenes")
    elif dataset_name == 'waymo_sample':
        logger.warning("âš ï¸ WaymoëŠ” Google Cloud ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        logger.info("ğŸŒ ê³µì‹ ì‚¬ì´íŠ¸: https://waymo.com/open/")
    else:
        logger.warning("âš ï¸ í•´ë‹¹ ë°ì´í„°ì…‹ì€ ì œí•œì  ì ‘ê·¼ì…ë‹ˆë‹¤.")
    
    logger.info("ğŸ¨ ëŒ€ì‹  í•´ë‹¹ í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    
    # í•©ì„± ë°ì´í„° ìƒì„±
    create_synthetic_diverse_data(dataset_dir, dataset_name, num_samples)
    
    return True

def main():
    parser = argparse.ArgumentParser(
        description="ğŸŒ ë‹¤ì–‘í•œ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë”",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ ë³´ê¸°
  python scripts/download_other_datasets.py --list

  # íŠ¹ì • ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
  python scripts/download_other_datasets.py --dataset nuscenes_mini
  python scripts/download_other_datasets.py --dataset waymo_sample
  python scripts/download_other_datasets.py --dataset cadc_winter

  # ì—¬ëŸ¬ ë°ì´í„°ì…‹ í•œë²ˆì—
  python scripts/download_other_datasets.py --dataset nuscenes_mini waymo_sample

  # ëª¨ë“  ë°ì´í„°ì…‹
  python scripts/download_other_datasets.py --dataset all

  # ë” ë§ì€ ìƒ˜í”Œë¡œ
  python scripts/download_other_datasets.py --dataset nuscenes_mini --num_samples 50

ì¶”ì²œ ì‚¬ìš©ë²• (ëª¨ë¸ ì¼ë°˜í™” í…ŒìŠ¤íŠ¸):
  1. python scripts/download_other_datasets.py --dataset nuscenes_mini    # ë„ì‹œ í™˜ê²½
  2. python scripts/download_other_datasets.py --dataset cadc_winter     # ê²¨ìš¸ í™˜ê²½  
  3. python scripts/download_other_datasets.py --dataset oxford_robotcar # ë¹„ í™˜ê²½
        """
    )
    
    parser.add_argument('--dataset', nargs='+', 
                        choices=list(DATASETS.keys()) + ['all'],
                        help="ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ì…‹(ë“¤)")
    parser.add_argument('--output_dir', type=str, default='data/other_datasets',
                        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: data/other_datasets)")
    parser.add_argument('--num_samples', type=int, default=20,
                        help="ìƒì„±í•  ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸: 20)")
    parser.add_argument('--list', action='store_true',
                        help="ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ í‘œì‹œ")
    parser.add_argument('--verbose', action='store_true',
                        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging()
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    if args.list:
        show_available_datasets()
        return 0
    
    if not args.dataset:
        logger.error("âŒ ë°ì´í„°ì…‹ì„ ì§€ì •í•´ì£¼ì„¸ìš”. --listë¡œ ëª©ë¡ì„ í™•ì¸í•˜ì„¸ìš”.")
        return 1
    
    try:
        logger.info("ğŸŒ ë‹¤ì–‘í•œ í™˜ê²½ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹œì‘")
        logger.info("ğŸ¯ ëª©ì : KITTI í›ˆë ¨ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        
        datasets_to_download = args.dataset
        if 'all' in datasets_to_download:
            datasets_to_download = list(DATASETS.keys())
        
        success_count = 0
        
        for dataset_name in datasets_to_download:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“Š {dataset_name.upper()} ì²˜ë¦¬ ì¤‘...")
            logger.info(f"{'='*60}")
            
            if download_dataset(dataset_name, args.output_dir, args.num_samples):
                success_count += 1
                logger.info(f"âœ… {dataset_name} ì™„ë£Œ")
            else:
                logger.error(f"âŒ {dataset_name} ì‹¤íŒ¨")
        
        logger.info(f"\nğŸ‰ ì™„ë£Œ! {success_count}/{len(datasets_to_download)} ë°ì´í„°ì…‹ ì¤€ë¹„ë¨")
        logger.info(f"ğŸ“‚ ê²½ë¡œ: {os.path.abspath(args.output_dir)}")
        
        if success_count > 0:
            logger.info("\nğŸ’» ì‚¬ìš© ë°©ë²•:")
            logger.info("# ê° ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸:")
            for dataset_name in datasets_to_download[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                if dataset_name != 'all':
                    dataset_path = os.path.join(args.output_dir, dataset_name)
                    logger.info(f"python scripts/run_evaluation.py --config configs/default_config.py --data_path {dataset_path}")
        
        return 0 if success_count > 0 else 1
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 